{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CultureScope: Cultural Specificity Classification (LM-Based Approach)\n",
    "\n",
    "**Task:** Classify items into three cultural specificity categories:\n",
    "- `cultural agnostic` - Universally known, no specific cultural ownership\n",
    "- `cultural representative` - Associated with a culture but known globally\n",
    "- `cultural exclusive` - Known primarily within a specific culture\n",
    "\n",
    "**Model:** Fine-tuned DeBERTa-v3-base transformer\n",
    "\n",
    "**HuggingFace Model:** [ArchitRastogi/NLP_HW_LM_non_tuned](https://huggingface.co/ArchitRastogi/NLP_HW_LM_non_tuned)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q datasets huggingface_hub transformers torch pandas numpy scikit-learn hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login, whoami\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Setup complete.\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- CONFIGURATION -----\n",
    "\n",
    "# Input: Choose one of the following options\n",
    "USE_HUGGINGFACE_DATASET = True  # Set to False to use local CSV file\n",
    "INPUT_CSV_PATH = \"test.csv\"     # Path to input CSV (used if USE_HUGGINGFACE_DATASET=False)\n",
    "\n",
    "# HuggingFace dataset configuration\n",
    "HF_DATASET_NAME = \"sapienzanlp/nlp2025_hw1_cultural_dataset\"  # Dataset name on HuggingFace\n",
    "HF_DATASET_SPLIT = \"SET NAME\"                         # Split to use (e.g., \"test\", \"validation\")\n",
    "\n",
    "if USE_HUGGINGFACE_DATASET:\n",
    "    HF_TOKEN = \"\"  # Add HuggingFace token here, as the dataset is gated\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"Logged in as:\", whoami())\n",
    "\n",
    "# Model configuration\n",
    "HF_MODEL_REPO = \"ArchitRastogi/NLP_HW_LM_non_tuned\"  # LM model repository\n",
    "\n",
    "# Inference settings\n",
    "BATCH_SIZE = 32         # Batch size for inference\n",
    "MAX_LENGTH = 384        # Maximum sequence length\n",
    "\n",
    "# Output configuration\n",
    "OUTPUT_CSV_PATH = \"predictions_lm_approach.csv\"  # Output file path\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Input: {'HuggingFace Dataset' if USE_HUGGINGFACE_DATASET else INPUT_CSV_PATH}\")\n",
    "print(f\"  Model: {HF_MODEL_REPO}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Output: {OUTPUT_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from HuggingFace: sapienzanlp/nlp2025_hw1_cultural_dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24040818db1d491c83b7624933f73ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf439459c9434ce691948f4ee5f36107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/946k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a787c4bbbae43b0a67d51fbdb2a9525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid.csv:   0%|          | 0.00/45.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a5b9d989e94f20a5534b618db6ed13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67c069ecc8e4de0ade025cf70eb1698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 samples.\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q15786</td>\n",
       "      <td>1. FC Nürnberg</td>\n",
       "      <td>German sports club based in Nuremberg, Bavaria</td>\n",
       "      <td>entity</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports club</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q268530</td>\n",
       "      <td>77 Records</td>\n",
       "      <td>UK record label</td>\n",
       "      <td>entity</td>\n",
       "      <td>music</td>\n",
       "      <td>record label</td>\n",
       "      <td>cultural exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q216153</td>\n",
       "      <td>A Bug's Life</td>\n",
       "      <td>1998 animated film directed by John Lasseter a...</td>\n",
       "      <td>entity</td>\n",
       "      <td>comics and anime</td>\n",
       "      <td>animated film</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q593</td>\n",
       "      <td>A Gang Story</td>\n",
       "      <td>2011 film by Olivier Marchal</td>\n",
       "      <td>entity</td>\n",
       "      <td>films</td>\n",
       "      <td>film</td>\n",
       "      <td>cultural exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q192185</td>\n",
       "      <td>Aaron Copland</td>\n",
       "      <td>American composer, composition teacher, writer...</td>\n",
       "      <td>entity</td>\n",
       "      <td>performing arts</td>\n",
       "      <td>choreographer</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     item            name  \\\n",
       "0   http://www.wikidata.org/entity/Q15786  1. FC Nürnberg   \n",
       "1  http://www.wikidata.org/entity/Q268530      77 Records   \n",
       "2  http://www.wikidata.org/entity/Q216153    A Bug's Life   \n",
       "3     http://www.wikidata.org/entity/Q593    A Gang Story   \n",
       "4  http://www.wikidata.org/entity/Q192185   Aaron Copland   \n",
       "\n",
       "                                         description    type  \\\n",
       "0     German sports club based in Nuremberg, Bavaria  entity   \n",
       "1                                    UK record label  entity   \n",
       "2  1998 animated film directed by John Lasseter a...  entity   \n",
       "3                       2011 film by Olivier Marchal  entity   \n",
       "4  American composer, composition teacher, writer...  entity   \n",
       "\n",
       "           category    subcategory                    label  \n",
       "0            sports    sports club  cultural representative  \n",
       "1             music   record label       cultural exclusive  \n",
       "2  comics and anime  animated film  cultural representative  \n",
       "3             films           film       cultural exclusive  \n",
       "4   performing arts  choreographer  cultural representative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset columns:\n",
      "['item', 'name', 'description', 'type', 'category', 'subcategory', 'label']\n",
      "\n",
      "Dataset shape: (300, 7)\n"
     ]
    }
   ],
   "source": [
    "if USE_HUGGINGFACE_DATASET:\n",
    "    print(f\"Loading dataset from HuggingFace: {HF_DATASET_NAME}\")\n",
    "    dataset = load_dataset(HF_DATASET_NAME, split=HF_DATASET_SPLIT)\n",
    "    test_df = pd.DataFrame(dataset)\n",
    "    print(f\"Loaded {len(test_df)} samples.\")\n",
    "else:\n",
    "    print(f\"Loading dataset from: {INPUT_CSV_PATH}\")\n",
    "    test_df = pd.read_csv(INPUT_CSV_PATH)\n",
    "    print(f\"Loaded {len(test_df)} samples.\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample data:\")\n",
    "display(test_df.head())\n",
    "\n",
    "# Show column info\n",
    "print(\"\\nDataset columns:\")\n",
    "print(test_df.columns.tolist())\n",
    "print(f\"\\nDataset shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer from: ArchitRastogi/NLP_HW_LM_non_tuned\n",
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12d638fd3c5434db0340f0c0b18c391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73641fcd931e4a66ad57199e2ba7a7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87699f1f8204119b6697cae3d9b38ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c207e59e9c498c969acab37ab82f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3e324ca0da4392b2f1caa78eb8a99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tokenizer loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1063246d724816b1beaf6d863e8931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037a2a5573024054be4e9c0e8fedc21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded and moved to device\n",
      "\n",
      "Model configuration:\n",
      "  Number of labels: 3\n",
      "  Label mapping: {0: 'cultural agnostic', 1: 'cultural representative', 2: 'cultural exclusive'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading model and tokenizer from: {HF_MODEL_REPO}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_REPO)\n",
    "print(\"Tokenizer loaded\")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(HF_MODEL_REPO)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print(\"Model loaded and moved to device\")\n",
    "\n",
    "# Get label mappings\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  Number of labels: {model.config.num_labels}\")\n",
    "print(f\"  Label mapping: {id2label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8b2d0d797f4ad69102982e36c91d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 300 input texts\n",
      "\n",
      "Example input text:\n",
      "Item: 1. FC Nürnberg. Description: German sports club based in Nuremberg, Bavaria. Type: entity. Category: sports. Subcategory: sports club.\n"
     ]
    }
   ],
   "source": [
    "def create_input_text(row):\n",
    "    \"\"\"Create formatted input text from row data\"\"\"\n",
    "    parts = [f\"Item: {row['name']}\"]\n",
    "    \n",
    "    if pd.notna(row.get('description')) and str(row.get('description')).strip():\n",
    "        parts.append(f\"Description: {row['description']}\")\n",
    "    \n",
    "    if pd.notna(row.get('type')) and str(row.get('type')).strip():\n",
    "        parts.append(f\"Type: {row['type']}\")\n",
    "    \n",
    "    if pd.notna(row.get('category')) and str(row.get('category')).strip():\n",
    "        parts.append(f\"Category: {row['category']}\")\n",
    "    \n",
    "    if pd.notna(row.get('subcategory')) and str(row.get('subcategory')).strip():\n",
    "        parts.append(f\"Subcategory: {row['subcategory']}\")\n",
    "    \n",
    "    return \". \".join(parts) + \".\"\n",
    "\n",
    "# Create input texts\n",
    "print(\"Creating input texts...\")\n",
    "input_texts = [create_input_text(row) for _, row in tqdm(test_df.iterrows(), total=len(test_df))]\n",
    "\n",
    "print(f\"\\nCreated {len(input_texts)} input texts\")\n",
    "print(\"\\nExample input text:\")\n",
    "print(input_texts[0][:300] + \"...\" if len(input_texts[0]) > 300 else input_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference on 300 samples...\n",
      "Batch size: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acabbb4711604306ae1b22aea3821fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Inference complete!\n",
      "  Predicted 300 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting inference on {len(input_texts)} samples...\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "all_predictions = []\n",
    "all_confidences = []\n",
    "all_probabilities = []\n",
    "\n",
    "# Process in batches\n",
    "for i in tqdm(range(0, len(input_texts), BATCH_SIZE), desc=\"Inference batches\"):\n",
    "    batch_texts = input_texts[i:i + BATCH_SIZE]\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        batch_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Get predictions and probabilities\n",
    "    pred_classes = torch.argmax(probs, dim=-1).cpu().numpy()\n",
    "    batch_probs = probs.cpu().numpy()\n",
    "    \n",
    "    # Store results\n",
    "    for pred_class, prob_dist in zip(pred_classes, batch_probs):\n",
    "        pred_label = id2label[pred_class]\n",
    "        confidence = prob_dist[pred_class]\n",
    "        \n",
    "        all_predictions.append(pred_label)\n",
    "        all_confidences.append(confidence)\n",
    "        all_probabilities.append(prob_dist)\n",
    "\n",
    "print(f\"\\nInference complete!\")\n",
    "print(f\"  Predicted {len(all_predictions)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dataframe created\n",
      "Shape: (300, 10)\n",
      "\n",
      "Columns: ['item', 'name', 'description', 'type', 'category', 'subcategory', 'label', 'prob_cultural_agnostic', 'prob_cultural_representative', 'prob_cultural_exclusive']\n"
     ]
    }
   ],
   "source": [
    "# Create output dataframe\n",
    "output_df = test_df[['item', 'name', 'description', 'type', 'category', 'subcategory']].copy()\n",
    "output_df['label'] = all_predictions\n",
    "\n",
    "# Add probability columns\n",
    "for idx, class_label in id2label.items():\n",
    "    col_name = f'prob_{class_label.replace(\" \", \"_\")}'\n",
    "    output_df[col_name] = [p[idx] for p in all_probabilities]\n",
    "\n",
    "print(\"Output dataframe created\")\n",
    "print(f\"Shape: {output_df.shape}\")\n",
    "print(f\"\\nColumns: {output_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to: predictions_lm_approach.csv\n",
      "\n",
      "Prediction distribution:\n",
      "label\n",
      "cultural agnostic          125\n",
      "cultural representative     92\n",
      "cultural exclusive          83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q15786</td>\n",
       "      <td>1. FC Nürnberg</td>\n",
       "      <td>German sports club based in Nuremberg, Bavaria</td>\n",
       "      <td>entity</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports club</td>\n",
       "      <td>cultural exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q268530</td>\n",
       "      <td>77 Records</td>\n",
       "      <td>UK record label</td>\n",
       "      <td>entity</td>\n",
       "      <td>music</td>\n",
       "      <td>record label</td>\n",
       "      <td>cultural exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q216153</td>\n",
       "      <td>A Bug's Life</td>\n",
       "      <td>1998 animated film directed by John Lasseter a...</td>\n",
       "      <td>entity</td>\n",
       "      <td>comics and anime</td>\n",
       "      <td>animated film</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q593</td>\n",
       "      <td>A Gang Story</td>\n",
       "      <td>2011 film by Olivier Marchal</td>\n",
       "      <td>entity</td>\n",
       "      <td>films</td>\n",
       "      <td>film</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q192185</td>\n",
       "      <td>Aaron Copland</td>\n",
       "      <td>American composer, composition teacher, writer...</td>\n",
       "      <td>entity</td>\n",
       "      <td>performing arts</td>\n",
       "      <td>choreographer</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.wikidata.org/entity/Q265890</td>\n",
       "      <td>Aarwangen Castle</td>\n",
       "      <td>castle in Aarwangen in the canton of Bern, Swi...</td>\n",
       "      <td>entity</td>\n",
       "      <td>architecture</td>\n",
       "      <td>architectural structure</td>\n",
       "      <td>cultural exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://www.wikidata.org/entity/Q305718</td>\n",
       "      <td>abaya</td>\n",
       "      <td>simple, loose over-garment wore by humans, esp...</td>\n",
       "      <td>concept</td>\n",
       "      <td>fashion</td>\n",
       "      <td>traditional costume</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://www.wikidata.org/entity/Q337267</td>\n",
       "      <td>Academy of San Carlos</td>\n",
       "      <td>Located in Mexico City, it was the first major...</td>\n",
       "      <td>entity</td>\n",
       "      <td>visual arts</td>\n",
       "      <td>art gallery</td>\n",
       "      <td>cultural exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://www.wikidata.org/entity/Q15</td>\n",
       "      <td>Africa</td>\n",
       "      <td>continent</td>\n",
       "      <td>entity</td>\n",
       "      <td>geography</td>\n",
       "      <td>geographic location</td>\n",
       "      <td>cultural agnostic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://www.wikidata.org/entity/Q388170</td>\n",
       "      <td>African American literature</td>\n",
       "      <td>body of literature by Americans of African des...</td>\n",
       "      <td>entity</td>\n",
       "      <td>literature</td>\n",
       "      <td>literary genre</td>\n",
       "      <td>cultural representative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     item                         name  \\\n",
       "0   http://www.wikidata.org/entity/Q15786               1. FC Nürnberg   \n",
       "1  http://www.wikidata.org/entity/Q268530                   77 Records   \n",
       "2  http://www.wikidata.org/entity/Q216153                 A Bug's Life   \n",
       "3     http://www.wikidata.org/entity/Q593                 A Gang Story   \n",
       "4  http://www.wikidata.org/entity/Q192185                Aaron Copland   \n",
       "5  http://www.wikidata.org/entity/Q265890             Aarwangen Castle   \n",
       "6  http://www.wikidata.org/entity/Q305718                        abaya   \n",
       "7  http://www.wikidata.org/entity/Q337267        Academy of San Carlos   \n",
       "8      http://www.wikidata.org/entity/Q15                       Africa   \n",
       "9  http://www.wikidata.org/entity/Q388170  African American literature   \n",
       "\n",
       "                                         description     type  \\\n",
       "0     German sports club based in Nuremberg, Bavaria   entity   \n",
       "1                                    UK record label   entity   \n",
       "2  1998 animated film directed by John Lasseter a...   entity   \n",
       "3                       2011 film by Olivier Marchal   entity   \n",
       "4  American composer, composition teacher, writer...   entity   \n",
       "5  castle in Aarwangen in the canton of Bern, Swi...   entity   \n",
       "6  simple, loose over-garment wore by humans, esp...  concept   \n",
       "7  Located in Mexico City, it was the first major...   entity   \n",
       "8                                          continent   entity   \n",
       "9  body of literature by Americans of African des...   entity   \n",
       "\n",
       "           category              subcategory                    label  \n",
       "0            sports              sports club       cultural exclusive  \n",
       "1             music             record label       cultural exclusive  \n",
       "2  comics and anime            animated film  cultural representative  \n",
       "3             films                     film  cultural representative  \n",
       "4   performing arts            choreographer  cultural representative  \n",
       "5      architecture  architectural structure       cultural exclusive  \n",
       "6           fashion      traditional costume  cultural representative  \n",
       "7       visual arts              art gallery       cultural exclusive  \n",
       "8         geography      geographic location        cultural agnostic  \n",
       "9        literature           literary genre  cultural representative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save to CSV\n",
    "output_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "print(f\"Predictions saved to: {OUTPUT_CSV_PATH}\")\n",
    "\n",
    "# Show prediction distribution\n",
    "print(\"\\nPrediction distribution:\")\n",
    "print(output_df['label'].value_counts())\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "display(output_df[[\n",
    "    \"item\",\n",
    "    \"name\",\n",
    "    \"description\",\n",
    "    \"type\",\n",
    "    \"category\",\n",
    "    \"subcategory\",\n",
    "    \"label\",  \n",
    "]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence statistics\n",
    "confidences = np.array(all_confidences)\n",
    "\n",
    "print(\"Confidence Statistics:\")\n",
    "print(f\"  Mean: {confidences.mean():.4f}\")\n",
    "print(f\"  Std:  {confidences.std():.4f}\")\n",
    "print(f\"  Min:  {confidences.min():.4f}\")\n",
    "print(f\"  Max:  {confidences.max():.4f}\")\n",
    "print(f\"  Median: {np.median(confidences):.4f}\")\n",
    "\n",
    "# Confidence by class\n",
    "print(\"\\nConfidence by Predicted Class:\")\n",
    "for label in sorted(output_df['label'].unique()):\n",
    "    class_confidences = confidences[output_df['label'] == label]\n",
    "    print(f\"  {label:30s}: {class_confidences.mean():.4f} ± {class_confidences.std():.4f} (n={len(class_confidences)})\")\n",
    "\n",
    "# Low confidence predictions\n",
    "print(\"\\nLow Confidence Predictions:\")\n",
    "for threshold in [0.5, 0.6, 0.7]:\n",
    "    low_conf_count = (confidences < threshold).sum()\n",
    "    low_conf_pct = (low_conf_count / len(confidences)) * 100\n",
    "    print(f\"  Confidence < {threshold}: {low_conf_count:4d} ({low_conf_pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution\n",
    "if 'category' in output_df.columns:\n",
    "    print(\"Predictions by Category (Top 10):\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for category in output_df['category'].value_counts().head(10).index:\n",
    "        cat_data = output_df[output_df['category'] == category]\n",
    "        cat_dist = cat_data['label'].value_counts()\n",
    "        \n",
    "        print(f\"\\n{category} (n={len(cat_data)}):\")\n",
    "        for label, count in cat_dist.items():\n",
    "            pct = (count / len(cat_data)) * 100\n",
    "            print(f\"  {label:30s}: {count:3d} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type distribution\n",
    "if 'type' in output_df.columns:\n",
    "    print(\"Predictions by Type:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for item_type in output_df['type'].value_counts().index:\n",
    "        type_data = output_df[output_df['type'] == item_type]\n",
    "        type_dist = type_data['label'].value_counts()\n",
    "        \n",
    "        print(f\"\\n{item_type} (n={len(type_data)}):\")\n",
    "        for label, count in type_dist.items():\n",
    "            pct = (count / len(type_data)) * 100\n",
    "            print(f\"  {label:30s}: {count:3d} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most/Least Confident Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add confidence column for display\n",
    "display_df = output_df.copy()\n",
    "display_df['confidence'] = all_confidences\n",
    "\n",
    "print(\"Most Confident Predictions (Top 10):\")\n",
    "display(display_df.nlargest(10, 'confidence')[['name', 'label', 'confidence', 'category']])\n",
    "\n",
    "print(\"\\nLeast Confident Predictions (Bottom 10):\")\n",
    "display(display_df.nsmallest(10, 'confidence')[['name', 'label', 'confidence', 'category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrates the LM-based approach for cultural specificity classification using a fine-tuned transformer model.\n",
    "\n",
    "**Model:** DeBERTa-v3-base fine-tuned on cultural classification task\n",
    "\n",
    "**Output:** `predictions_lm_approach.csv` with predicted labels and class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INFERENCE COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOutput file: {OUTPUT_CSV_PATH}\")\n",
    "print(f\"Total predictions: {len(output_df)}\")\n",
    "print(f\"Mean confidence: {np.mean(all_confidences):.4f}\")\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Evaluation Against Ground Truth\n",
    "\n",
    "If your test data includes ground truth labels, run this cell to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if your test_df has a 'label' column with ground truth\n",
    "if 'label' in test_df.columns:\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "    \n",
    "    y_true = test_df['label'].values\n",
    "    y_pred = output_df['label'].values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"Evaluation Results:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Accuracy:     {acc:.4f}\")\n",
    "    print(f\"F1 (Macro):   {f1_macro:.4f}\")\n",
    "    print(f\"F1 (Weighted): {f1_weighted:.4f}\")\n",
    "    print(\"\\nPer-class Metrics:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=['cultural agnostic', 'cultural exclusive', 'cultural representative'])\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['True: Agnostic', 'True: Exclusive', 'True: Representative'],\n",
    "                         columns=['Pred: Agnostic', 'Pred: Exclusive', 'Pred: Representative'])\n",
    "    display(cm_df)\n",
    "else:\n",
    "    print(\"No ground truth labels found in test data. Skipping evaluation.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
